\documentclass[11pt]{beamer}

\author{Tom Hubrecht}
\title{Transmission d'informations entre la Terre et les sondes spatiales}
\date{269}

\usefonttheme[onlymath]{serif}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{csquotes}
\usepackage[backend=biber, style=numeric, citestyle=verbose, sorting=nyt]{biblatex}
\usepackage[french]{babel}
\usepackage{hyperref}

\usepackage{appendixnumberbeamer}
\usepackage{listings}
\usepackage{color}
\usepackage{lmodern}
\usepackage{ragged2e}
\usepackage{graphicx}
\usepackage{tikz}

\usepackage{amsmath}
\usepackage{amsmath}
\usepackage{amssymb}

\graphicspath{{./Images/}}

\usetikzlibrary{shapes,arrows}

\usetheme{Frankfurt}

%% Beamer Options %%
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{bibliography item}{}

\setbeamertemplate{footline}
{
	\leavevmode%
	\hbox{%
		\begin{beamercolorbox}[wd=.4\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
			\usebeamerfont{author in head/foot}\insertshortauthor
		\end{beamercolorbox}%
		\begin{beamercolorbox}[wd=.6\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
			\usebeamerfont{title in head/foot}\insertshorttitle\hspace*{3em}
			\insertframenumber{} / \inserttotalframenumber\hspace*{1ex}
		\end{beamercolorbox}}%
	\vskip0pt%
}

\setbeamertemplate{section page}
{
	\begin{beamercolorbox}[sep=12pt,center]{section title}
		\usebeamerfont{section title}\insertsection\par
	\end{beamercolorbox}
}

\setbeamertemplate{subsection page}
{
	\begin{beamercolorbox}[sep=10pt,left]{subsection title}
		\usebeamerfont{subsection title}\insertsubsection\par
	\end{beamercolorbox}
}


\AtBeginSection{\frame[plain, noframenumbering]{\sectionpage}}
\AtBeginSubsection{\frame[plain, noframenumbering]{\subsectionpage}}


%% Define colors for the listings %%
\definecolor{cred}{RGB}{255, 85, 85}
\definecolor{cgreen}{RGB}{85, 255, 85}
\definecolor{cblue}{RGB}{85, 85, 255}
\definecolor{cblack}{RGB}{0, 0, 0}
\definecolor{cwhite}{RGB}{255, 255, 255}


%% Listing Options %%
\lstdefinestyle{beamer}{
	backgroundcolor=\color{cwhite},   
	commentstyle=\color{cblack},
	keywordstyle=\color{cblue}\bfseries,
	numberstyle=\tiny\color{cblue},
	stringstyle=\color{cred},
	basicstyle=\ttfamily\tiny,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=3
}

\lstset{style=beamer}


%% Include the bibliography %%
\addbibresource{Bibliography.bib}


% Definition of blocks:
\tikzset{%
	block/.style    	= {draw, thick, rectangle, minimum height = 3em, minimum width = 3em},
	rsc/.style			= {draw, thick, rectangle, minimum height = 3em, minimum width = 4em},
	smallblock/.style 	= {draw, thick, rectangle, minimum height = 1em, minimum width = 1em, node distance = 2cm},
	sum/.style      	= {draw, circle, node distance = 1.5cm}, % Adder
	input/.style    	= {coordinate}, % Input
	output/.style   	= {coordinate} % Output
}

%Defining string as labels of certain blocks.
\newcommand{\inpt}{$\boldsymbol{\circ}$}


\begin{document}


\begin{frame}[plain]
	\maketitle
\end{frame}

\begin{frame}[plain]{Table des mati\`eres}
	\tableofcontents
\end{frame}


\section{Introduction}
\subsection{Probl\'ematique}


\begin{frame}{Exploration spatiale}
	\centering
	\includegraphics[scale=0.4]{VoyagerReverse}\\
	La sonde Voyager 2 communique avec la Terre alors qu'elle se trouve \`a 18 milliards de kilom\`etres.
\end{frame}


\subsection{Mod\'elisation}


\begin{frame}{Th\'eorie de l'information (C. Shannon)}
	\begin{tikzpicture}[auto, thick, node distance=2.5cm, >=triangle 45]
		\draw % Drawing the diagram of a communication system :
		node at (0, 0.9) {\small $Source$}
		node [block, name=source] {} 
		node at (2.5, 0.9) {\small $\acute{E}metteur$}
		node [block, right of=source] (emetteur) {}
		node at (4.5, 0.5) {\small $Canal$}
		node [smallblock, right of=emetteur] (canal) {}
		node at (6.5, 0.9) {\small $R\acute{e}cepteur$}
		node at (6.5, 0) [block] (recepteur) {}
		node at (9, 0.9) {\small $Destination$}
		node [block, right of=recepteur] (destination) {}
		node at (4.5, -3.1) [text width=2cm, text centered] {\small$Source$ $de$ $bruit$}
		node at (4.5, -2) [block] (bruit) {}
		;

		% Joining blocks. 
		% Commands \draw with options like [->] must be written individually
		\draw[->](source) -- node [below] {\scriptsize Message}(emetteur);
		\draw[->](emetteur) -- node [below] {\scriptsize Signal} (canal);
		\draw[->](canal) -- node [below] {\scriptsize Signal} (recepteur);
		\draw node at (5.3, -0.6) {\scriptsize re\c{c}u};
		\draw[->](recepteur) -- node [below] {\scriptsize Message} (destination);
		\draw[->] (bruit) -- (canal);
	\end{tikzpicture}
\end{frame}

\begin{frame}{Cas de l'espace}
	\begin{itemize}	
		\item Canal de propagation gaussien
		\item Capacit\'e : $C = W.\log_{2}(1 + \frac{E_b}{N_0}) \; bit.s^{-1}$
		\begin{itemize}
			\item[-] $W$ : nombre de bits \'emis par seconde
			\item[-] $\frac{E_b}{N_0}$ : rapport signal sur bruit
		\end{itemize}
	\end{itemize}
\end{frame}


\section{Codes correcteurs d'erreurs}
\subsection{Principe}


\begin{frame}{Principe}
	\begin{itemize}
		\item Permettre de contrer l'action du bruit
		\item Se rapprocher de la limite de Shannon
	\end{itemize}
\end{frame}

\begin{frame}{D\'efinitions}
	\begin{itemize}
		\item Taux de transmission : $R = \frac{\text{nombre de bits du message}}{\text{nombre de bits envoy\'es}}$
		\item Probabilit\'e a posteriori (PAP)
		\item Rapport de vraisemblance logarithmique (LLR) : $\Lambda(d_k) = \log(\frac{\mathbf{P}(d_k = 1)}{\mathbf{P}(d_k = 0)})$
		%\item Codage syst\'ematique
	\end{itemize}
\end{frame}


\subsection{Diff\'erentes m\'ethodes}


\begin{frame}{Plusieurs classes de codes}
	\begin{itemize}
		\item Turbocodes
		\item Codes LDPC (Low Density Parity Checks)
	\end{itemize}
\end{frame}

\begin{frame}{Plusieurs types de d\'ecodage}
	\begin{itemize}
		\item D\'ecodage dur (Hard Decoding)
		\item D\'ecodage \`a d\'ecision douce (Soft decoding)
	\end{itemize}
\end{frame}

\begin{frame}{Turbocodes}
	\centering
	
	\begin{tikzpicture}[auto, thick, >=triangle 45]
	\draw % Drawing the turbo encoder
	node at (0, 3) {\inpt}
	node at (0, 3.3) {\scriptsize $d_k$}
	node at (0.075, 3) [input] (stream) {}
	node at (2, 1.5) [input] (mid) {}
	node at (2, 0) [block] (interleaver) {\scriptsize Entrelaceur}
	node at (4, 1.5) [rsc] (rsc1) {Enc$_{1}$}
	node at (4, -1.5) [rsc] (rsc2) {Enc$_{2}$}
	node at (7, 3) [right] (xk) {$X_k$}
	node at (7, 1.5) [right] (y1k) {$Y_{1,k}$}
	node at (7, -1.5) [right] (y2k) {$Y_{2,k}$}
	;
	
	% Drawing the arrows
	\draw[->] (stream) -| (interleaver);
	\draw[->] (stream) -- (xk);
	\draw[->] (rsc1) -- (y1k);
	\draw[->] (rsc2) -- (y2k);
	\draw[->] (interleaver) |- (rsc2);
	\draw[->] (mid) -- (rsc1);
	\end{tikzpicture}
\end{frame}

\begin{frame}{D\'ecodage d'un message cod\'e \`a l'aide de turbocodes}
Soit $R_1^N$ le message re\c{c}u, $S_k$ l'\'etat de codeur apr\`es lecture du bit $X_k$\\
$\forall k \in \{1, N\}$ on calcule $\Lambda(x_k)$ \`a l'aide de $\alpha_k^i(m) = \dfrac{\mathbf{P}(X_k = i, S_k = m, R_1^k)}{\mathbf{P}(R_1^k)}.\mathbf{P}(X_k = i, S_k = m / R_1^k)$ et\\
$\beta_k(m) = \dfrac{\mathbf{P}(R_{k+1}^N / S_k = m)}{\mathbf{P}(R_{k+1}^N / R_1^k)}$\\
on obtient alors $\mathbf{P}(x_k = 1 | R_1^N)$ et $\mathbf{P}(x_k = 0 | R_1^N)$ d'o\`u $\Lambda(x_k)$\\
car $\mathbf{P}(x_k = i | R_1^N) = \sum\limits_m\alpha_k^i(m).\beta_k(m)$
\end{frame}

\begin{frame}{Codes LDPC}
	\begin{itemize}
		\item Sommes de contrôle
		\item Multiplication matricielle
		\item Utilisation de matrices peu denses
	\end{itemize}
\end{frame}

\begin{frame}{D\'ecodage d'un message cod\'e \`a l'aide d'un code LDPC}
	\begin{itemize}
		\item Traduction du message re\c{c}u \`a l'aide d'une fonction seuil
		\item Calcul des sommes au niveau des noeuds de contr\^ole
		\item Modification des noueds messagers reli\'es aux noeuds de contrôles non satisfaits
		\item It\'eration jus'\`a satisfaction des noeuds de contr\^ole o\`u it\'eration maximale atteinte
	\end{itemize}
\end{frame}


\section{Impl\'ementation des codes correcteurs}
\subsection{Repr\'esenter l'efficacit\'e des codes}


\begin{frame}{Choix de l'image}
	\begin{figure}
		\includegraphics[scale=0.8]{base}
		\caption{Juno, XKCD}
	\end{figure}
\end{frame}

\begin{frame}{Processus}
	\begin{itemize}
		\item Transformation de l'image en liste de bits
		\item Codage du message obtenu
		\item Rajout d'un bruit blanc de moyenne nulle et de variance $s^2$
		\begin{itemize}
			\item[] $x_k = (2.d_k - 1) + a_k$ o\`u $a_k \hookrightarrow \mathcal{N}(0, s)$
			\item[] $\frac{E_b}{N_0} = \frac{1}{s}$
		\end{itemize}
		\item Enregistrement du message bruit\'e
		\item D\'ecodage du message et enregistrement
		\item Recr\'eation des images obtenues \`a l'aide des listes de bits
	\end{itemize}
\end{frame}


\section{R\'esultats}
\subsection{Bruit faible}


\begin{frame}{$SNR_{dB} = 2.2$ dB}
	\begin{columns}
		\begin{column}{.3\textwidth}
			\begin{figure}
				\includegraphics[scale=0.4]{turbo_noisy_60}\\
				Avant d\'ecodage
			\end{figure}
		\end{column}
		\begin{column}{.3\textwidth}
			\begin{figure}
				\includegraphics[scale=0.4]{turbo_decoded_60}\\
				Apr\`es d\'ecodage avec turbocodes
			\end{figure}
		\end{column}
		\begin{column}{.3\textwidth}
			\begin{figure}
				\includegraphics[scale=0.4]{ldpc_basic_decoded_60}\\
				Apr\`es d\'ecodage avec codes LDPC
			\end{figure}
		\end{column}
	\end{columns}
\end{frame}


\subsection{Bruit \'elev\'e}


\begin{frame}{$SNR_{dB} = 0.97$ dB}
	\begin{columns}
		\begin{column}{.3\textwidth}
			\begin{figure}
				\includegraphics[scale=0.4]{turbo_noisy_80}\\
				Avant d\'ecodage
			\end{figure}
		\end{column}
		\begin{column}{.3\textwidth}
			\begin{figure}
				\includegraphics[scale=0.4]{turbo_decoded_80}\\
				Apr\`es d\'ecodage avec turbocodes
			\end{figure}
		\end{column}
		\begin{column}{.3\textwidth}
			\begin{figure}
				\includegraphics[scale=0.4]{ldpc_basic_decoded_80}\\
				Apr\`es d\'ecodage avec codes LDPC
			\end{figure}
		\end{column}
	\end{columns}
\end{frame}


\subsection{Taux d'erreur}


\begin{frame}{Taux d'erreur des deux codes}
	\centering
	\includegraphics[scale=0.6]{taux_erreur}
\end{frame}


\section*{Conclusion}



\appendix



\section{Bibliographie}

\begin{frame}[plain]
	\footnotesize
	\begin{itemize}
		\item[-] \cite{voyager}
		\item[-] \cite{shannon}
		\item[-] \cite{gallager}
		\item[-] \cite{turbocodes}
		\item[-] \cite{ccsds}
		\item[-] \cite{juno}
	\end{itemize}
\end{frame}


\section{Code Informatique}


\begin{frame}[plain, fragile]{Initialisation}
	\begin{lstlisting}[language=C]
    size_t n = X->n;
    s_list *alpha = csl(32*(n + 1), 32*(n + 1));
    s_list *beta = csl(16*(n + 1), 16*(n + 1));
    s_list *gamma = csl(32*(n + 1), 32*(n + 1));
    s_list *lambda = csl(32*(n + 1), 32*(n + 1));
    s_list *a = csl(n + 1, n + 1);
    double tmp[2];

    size_t d; // The value of the k-th bit
    size_t b; // The value of the k-th encoded bit
    size_t m; // The previous state of the register
    size_t i;
    double x;
    double y;

    alpha->list[0] = 1.0;
    alpha->list[1] = 1.0;
    a->list[0] = 1.0;
    a->list[n] = 1.0;
    beta->list[16*n] = 1.0;

    lambda->list[32 * n] = alpha->list[32 * n];
    lambda->list[1 + 32 * n] = alpha->list[1 + 32 * n];
	\end{lstlisting}
\end{frame}

\begin{frame}[plain, fragile]{Calcul des $\alpha$ et $\gamma$}
	\begin{lstlisting}[language=C]
	for(size_t k = 1; k <= n; k++) // k-th bit of the message
    {
        x = X->list[k - 1];
        y = Y->list[k - 1];

        for(size_t S = 0; S < 16; S++) // Register state of the encoder
        {
            d = 0;
            m = S/2 + (S & 8) ^ 8*((S & 1) ^ d);
            b = d ^ (m & 1) ^ (m & 4)/4 ^ (m & 8)/8;
            gamma->list[2*S + 32*k] = pTrans(x, d, s) * pTrans(y, b, s);
            i = 2*m + 32*(k-1);
            alpha->list[2*S + 32*k] = gamma->list[2*S + 32*k] *
                                        (alpha->list[i] + alpha->list[1 + i]);

            d = 1;
            m = S/2 + (S & 8) ^ 8*((S & 1) ^ d);
            b = d ^ (m & 1) ^ (m & 4)/4 ^ (m & 8)/8;
            gamma->list[1 + 2*S + 32*k] = pTrans(x, d, s) * pTrans(y, b, s);
            i = 2*m + 32*(k-1);
            alpha->list[1 + 2*S + 32*k] = gamma->list[1 + 2*S + 32*k] *
                                        (alpha->list[i] + alpha->list[1 + i]);
            a->list[k] += alpha->list[2*S + 32*k] + alpha->list[1 + 2*S + 32*k];
        }

        for(size_t S = 0; S < 16; S++)
        {
            alpha->list[2*S + 32*k] /=  a->list[k];
            alpha->list[1 + 2*S + 32*k] /= a->list[k];
        }
    }
	\end{lstlisting}
\end{frame}

\begin{frame}[plain, fragile]{Calcul des $\beta$ et $\lambda$}
	\begin{lstlisting}[language=C]
    for(int k = (n - 1); k > 0; k--)    // Compute the probabilities beta
    {
        for(size_t S = 0; S < 16; S++)
        {
            m = (2*S & 15) + ((S & 8)/8) ^ ((S & 4)/4);
            beta->list[S + 16*k] = beta->list[m + 16*(k + 1)] *
                                                gamma->list[2*m + 32*(k + 1)];

            m = (2*S & 15) + ((S & 8)/8) ^ (1 - (S & 4)/4);
            i = 2*m + 32*(k + 1);
            beta->list[S + 16*k] += beta->list[i / 2] * gamma->list[1 + i];
        }

        for(size_t S = 0; S < 16; S++)
        {
            beta->list[S + 16*k] /= a->list[k + 1];
            lambda->list[2*S + 32*k] = alpha->list[2*S + 32*k] *
                                                        beta->list[S + 16*k];
            lambda->list[1 + 2*S + 32*k] = alpha->list[1 + 2*S + 32*k] *
                                                        beta->list[S + 16*k];
        }

        tmp[0] = 0.0;
        tmp[1] = 0.0;

        for(size_t S = 0; S < 16; S++)
        {
            tmp[0] += lambda->list[2*S + 32*k];
            tmp[1] += lambda->list[1 + 2*S + 32*k];
        }

        llr->list[k - 1] = log(tmp[1] / tmp[0]);
	\end{lstlisting}
\end{frame}

\begin{frame}[plain, fragile]{Cr\'eation d'un code LDPC}
	\begin{lstlisting}[language=C]
h_matrix * create_base(size_t n, size_t j, size_t k)
{
    size_t m = (n * j) / k;
    h_matrix *res = chm(m, n);
    i_list *perm = cil(n, n);

    // Fill the first horizontal part of the matrix
    for (size_t i = 0; i < n; i++)
    {
        shm(res, 1, (i / k), i);
    }

    // Fill the j-1 other bands
    for (size_t i = 1; i < j; i++)
    {
        permutation(perm);
        for (size_t x = 0; x < n; x++)
        {
            shm(res, 1, ((perm->list[x] + i * n) / k), x);
        }
    }
    return res;
}
	\end{lstlisting}
\end{frame}

\begin{frame}[plain, fragile]{D\'ecodage d'un code LDPC}
	\begin{lstlisting}[language=C]
int decode_ldpc_a_basic(a_matrix *mat, h_list *mes, size_t nb_max)
{
    h_list *verif = product_a(mat, mes);
    i_list *count = cil(mes->n, mes->n);
    i_list *max_errors = cil(mes->n, mes->n);
    size_t iter = 0;
    char correct = is_all_nil(verif);
    while (!correct && (iter < nb_max))
    {
        set_all_i_list(count, 0);
        for (size_t i = 0; i < verif->n; i++)
        {
            if (verif->list[i])
            {
                for (size_t j = 0; j < mat->list_n[i]->n; j++)
                {
                    count->list[mat->list_n[i]->list[j]] ++;
                }}}
        // Flip the bits with the most errors
        max_i_list(count, max_errors);
        for (size_t i = 0; i < max_errors->n; i++)
        {
            mes->list[max_errors->list[i]] ^= 1;
        }
        iter ++;
        product_a_in_place(mat, mes, verif);
        correct = is_all_nil(verif);
    }
    // Free used lists
    free_h_list(verif);
    free_i_list(count);
    free_i_list(max_errors);
    return iter;
}
	\end{lstlisting}
\end{frame}


\section{Turbocodes}


\begin{frame}{Composant Enc}
	\centering

	\begin{tikzpicture}[auto, thick, node distance = 1.5cm, >=triangle 45, scale=0.95, transform shape]
		\draw % Drawing the RSC component
		node at (-0.5, 3) {\inpt}
		node at (-0.5, 3.3) {\scriptsize $d_k$}
		node at (-0.425, 3) [input] (stream) {\inpt}
		node at (0, 3) [input] (mid) {}
		node [sum, right of=stream] (s1) {$+$}
		node [smallblock, right of=s1] (m1) {$M_1$}
		node [smallblock, right of=m1] (m2) {$M_2$}
		node [smallblock, right of=m2] (m3) {$M_3$}
		node [smallblock, right of=m3] (m4) {$M_4$}
		node [sum, below of=m1] (s2) {$+$}
		node [sum, below of=m3] (s3) {$+$}
		node [sum, below of=m4] (s4) {$+$}
		node [sum, above of=m3] (s5) {$+$}
		node [right of=s4] (out) {$Y_k$}
		;
		
		% Drawing the arrows
		\draw[->] (stream) -- (s1);
		\draw[->] (s1) -- (m1);
		\draw[->] (s1) -- (m1);
		\draw[->] (m1) -- (m2);
		\draw[->] (m2) -- (m3);
		\draw[->] (m3) -- (m4);
		\draw[->] (m4) |- (s5);
		\draw[->] (m3) -- (s5);
		\draw[->] (mid) |- (s2);
		\draw[->] (m1) -- (s2);
		\draw[->] (s2) -- (s3);
		\draw[->] (m3) -- (s3);
		\draw[->] (s3) -- (s4);
		\draw[->] (m4) -- (s4);
		\draw[->] (s5) -| (s1);
		\draw[->] (s4) -- (out);
	\end{tikzpicture}
\vfill
	\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|}
		\hline
		$d_k$ & $\emptyset$ & 1 & 1 & 0 & 1 & 1 & 0 & 1 & 0 & 1\\
		\hline
		$S$ & 0 & 1 & 3 & 6 & 12 & 9 & 3 & 7 & 15 & 15\\
		\hline
		$Y_k$ & $\emptyset$ & 1 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0\\
		\hline
	\end{tabular}
\end{frame}


\subsection{D\'ecodage}


\begin{frame}{Processus de d\'ecodage}
	Le d\'ecodeur re\c{c}oit en entr\'ee trois variables r\'eelles pour le code avec $R = \frac{1}{3}$ :
	\begin{align*} \label{dec_input}
		x_k & = (2.X_k - 1) + a_k \\
		y_{1,k} & = (2.Y_{1,k} - 1) + b_k \\
		y_{2,k} & = (2.Y_{2,k} - 1) + c_k
	\end{align*}
	o\`u $a_k, b_k$ et $c_k$ sont des variables al\'eatoires suivant une loi normale de moyenne nulle et de variance $\sigma^2$
\end{frame}

\begin{frame}{Principe de d\'ecodage}
	On note $S_k$ l'\'etat de l'encodeur au moment k, $S_k = (a_k, a_{k-1}, a_{k-2}, a_{k-3})$ \\
	$S_0 = S_N = 0$ \\ \smallskip

	La sortie du canal fournie \`a l'entr\'ee du d\'ecodeur est la suite $R_1^N = (R_1,\ldots,R_k,\ldots,R_N)$
	o\`u $R_k = (x_k,y_{j,k})$ \\ \smallskip
	
	On introduit $\lambda_k^i(m) = \mathbf{P}(X_k = i, S_k = m / R_1^N)$, d'o\`u $\mathbf{P}(d_k = i / R_1^N) = \sum\limits_{m} \lambda_k^i$ et $\Lambda(X_k) = \log\left(\dfrac{\sum\limits_{m} \lambda_k^1}{\sum\limits_{m} \lambda_k^0}\right) $
\end{frame}

\begin{frame}
	On introduit des fonctions :
	\begin{itemize}
		\item $\alpha_k^i(m) = \dfrac{\mathbf{P}(X_k = i, S_k = m, R_1^k)}{\mathbf{P}(R_1^k)}.\mathbf{P}(X_k = i, S_k = m / R_1^k)$
		\item $\beta_k(m) = \dfrac{\mathbf{P}(R_{k+1}^N / S_k = m)}{\mathbf{P}(R_{k+1}^N / R_1^k)}$
		\item $\gamma_i(R_k, m', m) = \mathbf{P}(X_k = i, R_k, S_k = m/ S_{k-1} = m')$
	\end{itemize}
	On a de plus :\\
	$\lambda_k^i(m)=\frac{\mathbf{P}(X_k=i,S_k=m,R_1^k,R_{k+1}^N)}{\mathbf{P}(R_1^k,R_{k+1}^N)}$\\
	$=\frac{\mathbf{P}(X_k=i,S_k=m,R_1^k)}{\mathbf{P}(R_1^k)}.\frac{\mathbf{P}(R_{k+1}^N|X_k=i,S_k=m,R_1^k)}{\mathbf{P}(R_{k+1}^N|R_1^k)}$\\
	Ainsi, par ind\'ependance du message, $\mathbf{P}(R_{k+1}^N|X_k=i,S_k=m,R_1^k)=\mathbf{P}(R_{k+1}^N|S_k=m)$, d'o\`u $\lambda_k^i(m) = \alpha_k^i(m).\beta_k(m)$
\end{frame}

\begin{frame}
	\begin{align*}
		\alpha_k^i(m)=&\frac{\mathbf{P}(d_k=i,S_k=m,R_1^{k-1},R_k)}{\mathbf{P}(R_1^{k-1},R_k)}\\
		=&\frac{\mathbf{P}(d_k=i,S_k=m,R_k|R_1^{k-1})}{\mathbf{P}(R_k|R_1^{k-1})}
	\end{align*}
\end{frame}

\begin{frame}
	$\mathbf{P}(d_k=i,S_k=m,R_k|R_1^{k-1})=$\\
	$\sum\limits_{m'}\sum\limits_{j=0}^1\mathbf{P}(d_k=i,S_k=m,d_{k-1}=j,S_{k-1}=m',R_k|R_1^{k-1})$\\
	$=\sum\limits_{m'}\sum\limits_{j=0}^1\mathbf{P}(d_{k-1}=j,S_{k-1}=m'|R_1^{k-1})\times$\\
	$\qquad\mathbf{P}(d_k=i,S_k=m,R_k|d_{k-1}=j,S_{k-1}=m',R_1^{k-1})$\\
	$=\sum\limits_{m'}\sum\limits_{j=0}^1\alpha_{k-1}^j(m')\gamma_i(R_k, m', m)$\\
	De m\^eme, on a :\\
	$\mathbf{P}(R_k|R_1^{k-1})=\sum\limits_{m'}\sum\limits_{m}\sum\limits_{i=0}^1\sum\limits_{j=0}^1\alpha_{k-1}^j(m')\gamma_i(R_k, m', m)$, d'o\`u\\
	$\alpha_k^i(m)=\frac{\sum\limits_{m'}\sum\limits_{j=0}^1\alpha_{k-1}^j(m')\gamma_i(R_k,m',m)}{\sum\limits_{m'}\sum\limits_{m}\sum\limits_{i=0}^1\sum\limits_{j=0}^1\alpha_{k-1}^j(m')\gamma_i(R_k, m', m)}$
\end{frame}

\begin{frame}
	$\beta_k(m)=\frac{\sum\limits_{m'}\sum\limits_{i=0}^1\mathbf{P}(d_{k+1}=i,S_{k+1}=m',R_{k+1},R_{k+2}^N|S_k=m)}{\mathbf{P}(R_{k+1}^N|R_1^k)}$\\
	$=\frac{\sum\limits_{m'}\sum\limits_{i=0}^1\mathbf{P}(R_{k+2}^N|S_{k+1}=m')\mathbf{P}(d_{k+1}=i,S_{k+1}=m',R_{k+1},|S_k=m)}{\mathbf{P}(R_{k+1}^N|R_1^k)}$\\
	$=\frac{\sum\limits_{m'}\sum\limits_{i=0}^1\beta_{k+1}(m')\gamma_i(R_{k+1},m,m')}{\mathbf{P}(R_{k+1}|R_1^k)}$\\
	$=\frac{\sum\limits_{m'}\sum\limits_{i=0}^1\beta_{k+1}(m')\gamma_i(R_{k+1},m,m')}{\sum\limits_{m'}\sum\limits_{m}\sum\limits_{i=0}^1\sum\limits_{j=0}^1\alpha_{k}^j(m')\gamma_i(R_{k+1}, m', m)}$
\end{frame}

\begin{frame}
	
\end{frame}

\begin{frame}{Algorithme de calcul}
	\begin{itemize}
		\item[-] \'Etape 0 : On initialise les probabilit\'es, \\
					$\qquad \alpha_0^i(0) = 1, \; \alpha_0^i(m) = 0 \quad \forall m \neq 0$\\
					$\qquad \beta_N(0) = 1, \; \beta_N(m) = 0 \quad \forall m \neq 0$
		\item[-] \'Etape 1 : Pour chaque information re\c{c}ue $R_k$, on calcule $\alpha_k^i(m)$, $\gamma_i(R_k, m', m)$
		\item[-] \'Etape 2 : Apr\`es la r\'eception du message, on calcule  $\beta_k(m)$ puis  $\lambda_k^i(m)$ et enfin $\Lambda(X_k)$
	\end{itemize}
\end{frame}


\section{Codes LDPC}
\subsection{Fonctionnement}


\begin{frame}{Principe math\'ematique}
	\begin{itemize}
		\item[-] Le codage comme multiplication matricielle dans $\mathbb{F}_2$
		\item[-] Utilisation de matrices peu denses $A \in \mathcal{M}_n(\mathbb{F}_2)$
		\item[-] Code (n, j, k)
	\end{itemize}
\end{frame}

\begin{frame}{G\'en\'eration d'un code LDPC}
	Utilisation de la m\'ethode de Robert Gallager pour un code (n, j, k).
	\begin{equation*}
	\begin{split}
	& A =
	\begin{pmatrix}
	A_1 \\
	A_2 \\
	\vdots \\
	A_j	\\ \end{pmatrix} \quad
	A_1 =
	\begin{pmatrix}
	1 & 1 & 1 & 0 & \cdots & 0 & 0 \\
	0 & 0 & 0 & 1 & \cdots & 0 & 0 \\
	\vdots & & & & \cdots & & \vdots \\ 
	0 & 0 & 0 & 0 & \cdots & 1 & 1 \\ \end{pmatrix}\\ & \\
	& \forall l \in {2, j}, \quad A_i = \left(C_{\sigma(1)}|\ldots|C_{\sigma(j)}\right) \text{o\`u} \; A_1 = \left(C_1|\ldots|C_j\right)
	\end{split}
	\end{equation*}

	La matrice de codage obtenue est alors $G = \begin{pmatrix} A \\ I \end{pmatrix}$ et la matrice de d\'ecodage $H = \begin{pmatrix} A & I \end{pmatrix}$
\end{frame}

\begin{frame}{Codage d'un message}
	Soit $m = (m_1, \ldots, m_n)$  un message \`a coder, on a $c = (c_1,\ldots,c_r)$ le message obtenu apr\`es codage,\\
	$c = G.m^T$  o\`u $r = \dfrac{nj}{k} + n$,

	Le taux de transmition vaut donc $R = \dfrac{k}{k + j}$

	Enfin, $H.c^T = 0$
\end{frame}


\subsection{D\'ecodage}


\begin{frame}{Repr\'esentation de Tanner}
	Un graphe de Tanner est associ\'e \`a la matrice de d\'ecodage H et comprend :
	\begin{itemize}
		\item $r$ noeuds messagers
		\item $\frac{n.j}{k}$ noeuds de contr\^ole
	\end{itemize}

	\centering

	\begin{tikzpicture}[auto, thick, node distance=1cm]
		\draw % Drawing the Tanner graph
		% Noeuds messagers
		node at (4.5, 4) {\textbf{Noeuds messagers}}
		node at (0, 3) [sum] (m1) {}
		node at (0, 3.4) {\scriptsize $m_1$}
		node [sum, right of=m1] (m2) {}
		node at (1.5, 3.4) {\scriptsize $m_2$}
		node [sum, right of=m2] (m3) {}
		node at (3, 3.4) {\scriptsize $m_3$}
		node at (4.5, 3) {$\cdots$}
		node at (6, 3) [sum] (m4) {}
		node at (6, 3.4) {\scriptsize $m_{r-1}$}
		node [sum, right of=m4] (m5) {}
		node at (7.5, 3.4) {\scriptsize $m_{r}$}
		% Noeuds de contrôle
		node at (4.5, 0) {\textbf{Noeuds de contr\^ole}}
		node at (0.75, 1) [smallblock] (c1) {}
		node at (0.75, 0.5) {\scriptsize $c_1$}
		node at (2.25, 1) [smallblock] (c2) {}
		node at (2.25, 0.5) {\scriptsize $c_2$}
		node at (4.5, 1) {$\cdots$}
		node at (6.75, 1) [smallblock] (c3) {}
		node at (6.75, 0.5) {\scriptsize $c_{\frac{nj}{k}}$}
		;
		
		% Drawing the links
		\draw[-] (c1.north) -- (m1);
		\draw[-] (c1.north) -- (m2);
		\draw[-] (c2.north) -- (m1);
		\draw[-] (c2.north) -- (m3);
		\draw[-] (m2) -- (3.7, 2.2);
		\draw[-] (c3.north) -- (m4);
		\draw[-] (c3.north) -- (m5);
		\draw[-] (c3.north) -- (5.3, 1.8);
	\end{tikzpicture}
\end{frame}

\end{document}
